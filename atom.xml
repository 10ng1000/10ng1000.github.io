<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>10ng&#39;s Own NG</title>
  
  
  <link href="https://10ng1000.github.io/atom.xml" rel="self"/>
  
  <link href="https://10ng1000.github.io/"/>
  <updated>2023-11-29T07:50:32.000Z</updated>
  <id>https://10ng1000.github.io/</id>
  
  <author>
    <name>10ng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用LLM和doccano进行关系抽取和验证</title>
    <link href="https://10ng1000.github.io/2023/11/29/RE/"/>
    <id>https://10ng1000.github.io/2023/11/29/RE/</id>
    <published>2023-11-29T03:57:41.000Z</published>
    <updated>2023-11-29T07:50:32.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a><strong>关系抽取</strong></h1><p>在企业项目中，需要对制冷这一冷门领域的操作指南和说明文档进行关系抽取。为此笔者尝试了许多传统方法的模型，但效果都欠佳。受到当下在NLP（Natural Language Processing，自然语言处理）中流行且功能强大的LLM（Large Language Model，大语言模型）的启发，笔者尝试了使用本地和API的大模型进行关系抽取，取得了相对于传统方法较好的效果。</p><h2 id="使用传统深度学习方法的关系抽取的不足"><a href="#使用传统深度学习方法的关系抽取的不足" class="headerlink" title="使用传统深度学习方法的关系抽取的不足"></a><strong>使用传统深度学习方法的关系抽取的不足</strong></h2><p>起初，笔者尝试了使用传统深度学习方法进行关系抽取。基本思路是使用IDCNN&#x2F;biLSTM和CRF进行实体检测，然后使用biGRU和attention机制进行特征提取。但是传统深度学习方法有两个基本的问题：</p><ul><li>在冷门领域不具备zero-shot能力。训练这些模型的训练集（如DUIE）相对于LLM来说还是太少，而且预训练数据显然没有覆盖到制冷领域相关的知识。于是这些模型在制冷领域中都不能够提取出关系。</li><li>可用的训练数据较少。制冷领域可用的有标签训练数据太少，不足以训练出可用的模型。</li></ul><p>笔者测试了<a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/information_extraction/DuIE">DuIE</a>，<a href="https://www.modelscope.cn/models/damo/nlp_structbert_siamese-uninlu_chinese-base/summary">SiameseUniNLU</a>等主流模型，都无法在企业项目的文档中提取出任何的关系。</p><h2 id="使用-LLM进行关系抽取"><a href="#使用-LLM进行关系抽取" class="headerlink" title="使用 LLM进行关系抽取"></a><strong>使用 LLM进行关系抽取</strong></h2><p>当下，大语言模型得到了越来越多的使用，同时开源大语言模型的效果也在逐步提高。论文<a href="https://arxiv.org/pdf/2302.10205.pdf">Zero-Shot Information Extraction via Chatting with ChatGPT</a> 中的研究表明：在两个语言的6个数据集上的实验结果表明，使用ChatGPT等LLM的关系抽取取得了非常好的效果，甚至在几个数据集上（例如NYT11-HRL）上超过了全监督模型的表现。出于这篇论文的启发，笔者使用LLM进行关系抽取。</p><h3 id="LLM模型大小的影响"><a href="#LLM模型大小的影响" class="headerlink" title="LLM模型大小的影响"></a><strong>LLM模型大小的影响</strong></h3><p>首先，笔者在文心一言的网页对话上进行了初步尝试，发现了这个思路是可行的。</p><p><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0001.png"><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0002.png"></p><p>但是，商用大模型由于参数量更大、使用的计算资源更多、训练数据也更大，本地的开源大模型效果肯定比不上商用API。因此笔者在本地部署了一些主流的开源大模型，以测试是否可行。</p><p>笔者在ChatGLM3-6B-Chat，Baichuan2-13B-Chat和Baichuan2-13B-Chat-4bits量化版上都进行了实验，发现模型参数量的大小会显著地影响得出的效果。在企业项目的文档中，对于笔者准备好的相同的prompt，ChatGLM3-6B-Chat的关系抽取效果一般，难以提取出完整实体。Baichuan2-13B-Chat-4bits量化版本表现则更优，已经可以提取出较为准确的实体和关系，精度更高的Baichuan2-13B-Chat模型效果也符合预期地达到了更佳的表现。同时，商用大模型文心一言网页版得到了最理想的效果。通过实验可以发现，基本上关系抽取的效果是与LLM本身的能力（通常和参数大小正相关）是成正相关的。</p><p><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0003.png"><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0004.png"></p><p><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0005.png"><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0006.png"></p><p><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0007.png"><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0008.png"></p><h3 id="Prompt编写"><a href="#Prompt编写" class="headerlink" title="Prompt编写"></a><strong>Prompt编写</strong></h3><p>参考了论文<a href="https://arxiv.org/pdf/2302.10205.pdf">Zero-Shot Information Extraction via Chatting with ChatGPT</a>中prompt的编写方式，以及在Baichuan2上的实验，最终对于无schema的关系提取，笔者得出这个模板：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">假设你是一个实体关系抽取模型，你需要抽取出接下来用三重反引号限定的句子中成对的关系实体。该句子来源于&#123;context&#125;中。抽取出的每个关系需要完全符合&#123;&#123;<span class="string">&quot;subject&quot;</span>:主体, <span class="string">&quot;subject_type&quot;</span>:<span class="string">&quot;主体类型&quot;</span>, <span class="string">&quot;relation&quot;</span>:<span class="string">&quot;联系&quot;</span>, <span class="string">&quot;object&quot;</span>:<span class="string">&quot;客体&quot;</span>, <span class="string">&quot;object_type&quot;</span>:<span class="string">&quot;客体类型&quot;</span>&#125;&#125;的JSON格式，主体类型、联系和客体类型的值都必须是中文，主体和客体必须完整摘自句子中，主体和客体越长、越完整越好。最后只输出符合JSON格式的结果。</span><br><span class="line">```&#123;line&#125;```</span><br></pre></td></tr></table></figure><p>这里对该prompt进行说明：</p><p>Prompt中的{context}可以是文档名字，或者这个文档的主体内容。经过实验，笔者发现给定文档名称可以让LLM更好地理解文档中的句子。</p><p>接下来笔者指定了LLM输出JSON格式的结果。通过指定找出的关系所需的格式，LLM可以给出一个较为标准的回答，便于后续的处理。而且经过实验笔者发现，在有了给定的回答格式之后，LLM的关系抽取表现也会变好。</p><p>同时笔者在实验过程中发现，LLM在遇到文档中的英文部分时，回答可能会以英文形式给出，因此笔者在prompt中限定了输出需要是中文。需要注意的是，较小的模型即使给定了这个限定，也可能不会得到像预期一样的输出。</p><p>笔者在这里加上主体和客体必须完整摘自句子中的指令，这是因为笔者之后需要把输出内容上传到doccano标注工具上，笔者需要保证实体和客体出自原句，以便找出其在原句中的位置。</p><p>Prompt中还强调了主体和客体越长、越完整越好，这个是可选的选项，经过实验笔者发现，如果加上这句话，LLM会从一个更大局的角度来找出句子中的关系，这更符合企业项目中说明文档关系提取的需求。如果去掉这句话，找出来的关系会偏向于局部的关系。需要注意的是，对于Baichuan2-13B这类较小的LLM，由于模型理解能力有限，它可能还是无法提取出符合句子中心思想的关系。但是文心一言等商用大模型就可以做到。</p><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a><strong>数据处理</strong></h3><p>由于LLM可以直接以自然语言作为输入，数据预处理工作稍微简化了一些。笔者需要考虑的问题是，对于较长的输入文本，是应该以<strong>段落</strong>还是<strong>句子</strong>为标准作为关系抽取的输入。以段落为标准进行关系抽取可以让LLM更全面地了解一个句子的意思，而且可以降低LLM的指示prompt和输入prompt的比值，提高推理效率。但是，这种方法需要占用较大的显存，一些机器可能不能满足这样高的显存要求。另外，如果是要提取文本段的核心关系，考虑是以段落还是以句子为标准，可以从不同粒度提取想要的结果。经过测试，两种标准都能有较好的关系抽取效果。因此，在机器显存足够的情况下，使用段落作为标准进行关系抽取效果更好。</p><p>读取文档后，再去除空行，以避免计算资源的浪费。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_file = <span class="built_in">open</span>(<span class="string">&quot;./2023/11/29/RE/data/data_0.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">data = data_file.readlines()</span><br><span class="line">data = [line <span class="keyword">for</span> line <span class="keyword">in</span> data <span class="keyword">if</span> line != <span class="string">&quot;\n&quot;</span>]</span><br></pre></td></tr></table></figure><p>笔者让LLM输出符合JSON格式的结果，以便下游任务使用。</p><p>但是对于LLM，尤其是本地部署的参数较小的LLM，即使在prompt中明确给出了任务要求的输出格式，仍然会出现输出不符合要求的情况，如果不进行处理会对下游工作造成一定的麻烦。</p><p>经过实验，笔者发现LLM可能会出现以下形式的非法输出：在开始或结尾输出类似“好的，接下来我将进行关系抽取任务”的冗余信息；在最后一个JSON对象后加上逗号；输出的[]号不匹配；输出的JSON对象之间没有逗号；输出不符合要求的键值对；由于提取不出关系，输出的内容中不包含JSON。</p><p>起初笔者尝试了使用python的字符串删减，替换方式来处理，但是通过实验发现，对于LLM输出的不稳定结果，这种操作方法的鲁棒性太差。后来笔者发现，既然笔者的核心目标是LLM输出的JSON语句，那么笔者实际上可以直接提取符合JSON格式的语句段。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">relations = re.findall(<span class="string">r&#x27;(&#123;\s*?\n\s*?&quot;subject&quot;:.*?,\s*?&quot;subject_type&quot;:.*?,\s*?&quot;relation&quot;:.*?,\s*?&quot;object&quot;:.*?,\s*?&quot;object_type&quot;:.*?\s*?&#125;)&#x27;</span>, response)</span><br></pre></td></tr></table></figure><p>这个正则表达式会匹配（几乎）符合要求的JSON对象，由于输出的内容中可能不包含JSON，需要再加上控制判断。</p><p>然后用replace来解决最后一个JSON对象后加上逗号的问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = re.sub(<span class="string">r&quot;,\s*?\n?\s*?&#125;&quot;</span>, <span class="string">&quot;\n&#125;&quot;</span>, response)</span><br></pre></td></tr></table></figure><p>找到符合条件的JSON对象后，只需要再用python的字符串方法把它们拼接起来，最终就可以形成一个可用的JSON。</p><h3 id="基于schema和无schema的关系抽取"><a href="#基于schema和无schema的关系抽取" class="headerlink" title="基于schema和无schema的关系抽取"></a><strong>基于schema和无schema的关系抽取</strong></h3><p>在关系抽取任务中，schema，也就是诸如(人名-编写-小说)这样的关系模式，可以用来限制和指导关系抽取模型抽取关系。而LLM相对于传统深度学习的关系抽取模型来说，还拥有无schema进行关系抽取的能力；也就是说，LLM会自动地根据任务需要和上下文提取出合适地关系，而不限定是什么模式。基于schema进行关系抽取可以让LLM抽取出笔者想要的特定模式，适合笔者有明确的抽取目标的场景；而无schema的关系抽取可以节省相关人员的工作量，也可以更好地发挥大模型的理解能力，缺点是抽取出的关系和实体标签可能比较繁杂。</p><p>通过实验笔者发现，对于企业项目中说明文档性质的内容，在使用Baichuan2-13B模型的情况下，如果使用基于schema的关系抽取，LLM回答的内容的置信度会下降很多，经常出现强行匹配schema的情况，而且即使是符合schema的关系，效果也只是一般。而如果不使用schema则不会有这种情况发生，因此笔者默认使用无schema的模式，如果要使用基于schema的模式，可以参考<a href="https://github.com/cocacola-lab/ChatIE">ChatIE</a>中的Prompt。</p><h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a><strong>其他问题</strong></h3><p>如果使用Baichuan2-13B等本地开源模型，且机器性能一般，只能勉强运行的话，对于较长的句子，LLM可能会卡死，即使过了十几二十分钟也不会输出结果。因此，笔者使用了timeout_decorator库来为推理设置超时时间（只在Linux平台上有效）。同时在JSON文件记录了输出对应于原始文本的位置index。</p><p>因为长文本处理随时都有可能因为各种异常原因暂停，笔者把程序断开时所在的index记录为check_point，以使得程序在断开后能从断开的句子处继续写入。</p><p>由于大模型输出结果的不稳定性，最后的文档可能还不是标准的JSON格式，需要再进行JSON校验。</p><h1 id="doccano标注"><a href="#doccano标注" class="headerlink" title="doccano标注"></a><strong>doccano标注</strong></h1><p>由于不管是传统深度学习模型还是大语言模型，都无法完美地提取出期望的结果，笔者使用了开源的文档标注工具<a href="https://github.com/doccano/doccano">doccano</a>，以实现人在回路进行关系的校验和增删。由于要将LLM的不稳定输出提交到需要稳定输入的doccano标注工具上，笔者编写相关转换和处理的Python代码。</p><h2 id="doccano客户端"><a href="#doccano客户端" class="headerlink" title="doccano客户端"></a><strong>doccano客户端</strong></h2><p>连接doccano需要token鉴权，因此首先需要知道doccano部署的ip和端口，以及username和password。笔者使用下面的代码来进行客户端的初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Client</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, entrypoint, password</span>):</span><br><span class="line">    <span class="variable language_">self</span>.entrypoint = entrypoint</span><br><span class="line">    <span class="variable language_">self</span>.client = requests.Session()</span><br><span class="line">    <span class="variable language_">self</span>.client.auth = (username, password)</span><br><span class="line">    token = <span class="variable language_">self</span>.client.request(<span class="string">&quot;POST&quot;</span>,<span class="string">f&#x27;<span class="subst">&#123;self.entrypoint&#125;</span>/v1/auth/login/&#x27;</span>, json=&#123;<span class="string">&#x27;username&#x27;</span>: username, <span class="string">&#x27;password&#x27;</span>: password&#125;).cookies[<span class="string">&#x27;csrftoken&#x27;</span>]</span><br><span class="line">    <span class="variable language_">self</span>.client.headers.update(&#123;<span class="string">&#x27;X-CSRFToken&#x27;</span>: token&#125;)</span><br></pre></td></tr></table></figure><p>Client类中定义的其他方法用于对doccano客户端的增删改查操作。</p><p>在Doccano中，一个项目（project）是拥有共同标签集的文本集的概念，一个文档（document）是一个用于标注的文本。标签（labels）包括实体标签和联系标签，实体标签和关系标签分别用span-type和relation-type表示。一个标注实体用（span）表示，记录相关实体的起始和结束偏移量，以及实体标签；一个标注关系用（relation）表示，记录头实体，尾实体和关系标签。</p><h2 id="数据处理-1"><a href="#数据处理-1" class="headerlink" title="数据处理"></a><strong>数据处理</strong></h2><p>首先，笔者需要对<a href="#_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86">数据处理</a>中得到的JSON格式输出进行人工确认，确保符合JSON格式，一般只需要修改几处异常即可（其中，重复的键值对无需处理，Python的json库自动取最后一个值）。</p><p>笔者还需要读取原始文本，然后指定文章的划分方法，这里一般是换行符或者句号。</p><p>接下来是读取JSON格式的输出文本，然后需要删除不符合条件的关系。笔者删除掉缺少由prompt指定的必要的JSON关键字的响应，因为这通常隐含了这个提取效果不够好，才会缺少某一个关键字。同样的，当键值对的值不为字符串、键值对的值为空时，笔者也删除掉这个关系。笔者不关注多余的键值对（例如，LLM会提取出“evidence”，“object_part”这样不符合要求的键），因为笔者直接忽视这部分即可（也提供了像上述一样删除的选项）。</p><h2 id="上传标签"><a href="#上传标签" class="headerlink" title="上传标签"></a><strong>上传标签</strong></h2><p>如果之前没有上传过标签，笔者就把JSON输出的所有实体类型、关系、联系类型都上传到doccano服务器上。Doccano会自动屏蔽掉重复的标签，所以无需额外处理。如果要删除标签，可以调用client的响应函数。</p><h2 id="获取标签id"><a href="#获取标签id" class="headerlink" title="获取标签id"></a><strong>获取标签id</strong></h2><p>在doccano中，笔者是通过标签的id来操作标签的，而不是用标签的名称。而id又是doccano指定的，所以笔者需要事先从doccano获得标签，并把标签和对应文本的键值对保存到内存里，以便后续上传实体和关系时使用。</p><h2 id="上传实体和关系"><a href="#上传实体和关系" class="headerlink" title="上传实体和关系"></a><strong>上传实体和关系</strong></h2><h3 id="实体位置的计算"><a href="#实体位置的计算" class="headerlink" title="实体位置的计算"></a><strong>实体位置的计算</strong></h3><p>上传实体时最主要的问题就是实体位置的计算。因为doccano记录实体在文章中的位置，以便于进行检验和修改，所以笔者需要上传正确的实体位置。</p><p>这一部分工作（还有之前相当一部分的工作）笔者没有交给LLM来做，因为这类有确切结果，且容易编写算法求解的工作，编写对应的Python脚本来解决，可以既保证结果的准确性又减少算力的浪费。</p><p>笔者使用一个变量global_offset来记录实体在文章中的实际偏移量。对于LLM输出的JSON文档中对于每一个文本段给出的所有回复，笔者都尝试找出这个回复中的实体和客体第一次出现在这个文本段的位置（因为同样名称的实体在一个文本段中几乎可以肯定是相同含义的），如果找不到这个实体（通常是因为LLM的模型较小，而忽视了笔者的要求），笔者通过匹配前若干个相同的字符来找到文本段的位置（同样是因为文本段较小，几乎不会找错专有实体）。如果确实找不到这个实体（几乎不会出现），笔者也就只能跳过这个句子。最终，这个实体的实际起始偏移量和实际结束偏移量结合global_offset和实体的长度就都可以计算出来了</p><p>在每个句子处理完后，笔者把global_offset加上这个句子的长度。需要注意的一个细节是，由于LLM可能对于某些文段没有输出，笔者需要把跳过对应的句子的长度也都加起来。</p><h3 id="重复实体的处理"><a href="#重复实体的处理" class="headerlink" title="重复实体的处理"></a><strong>重复实体的处理</strong></h3><p>对于每个句子，一个实体可能会在多个关系中出现，而doccano不会对重复的实体进行过滤（这是因为一个实体可能有多个类型，但是实际上doccano对于相同的类型也不会过滤），因此笔者需要判断是否已经上传过了这个实体，否则标注的结果会很混乱。这里判断相同的依据是：起始偏移量、结束偏移量和标签都相同。</p><p>这样做还有一个额外的好处。当程序因为各种原因断开时，笔者可以简单地从头执行这个程序，因为重复的实体不会被重复上传。</p><h3 id="上传"><a href="#上传" class="headerlink" title="上传"></a><strong>上传</strong></h3><p>所有的上述工作做完后，笔者就可以上传实体和关系了。上传实体时只需要上传初始、结束偏移量和实体标签id，上传关系时只需要上传头尾实体id和标签id。对于重复的关系，doccano会自动过滤掉。</p><p><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0009.png"><img src="/./2023/11/29/RE/AsposeWords2f6cad52-b522-451f-bc0b-541f2ef53fa0010.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;关系抽取&quot;&gt;&lt;a href=&quot;#关系抽取&quot; class=&quot;headerlink&quot; title=&quot;关系抽取&quot;&gt;&lt;/a&gt;&lt;strong&gt;关系抽取&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;在企业项目中，需要对制冷这一冷门领域的操作指南和说明文档进行关系抽取。为此笔者尝试了许多传</summary>
      
    
    
    
    
    <category term="知识图谱，LLM，doccano" scheme="https://10ng1000.github.io/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%EF%BC%8CLLM%EF%BC%8Cdoccano/"/>
    
  </entry>
  
  <entry>
    <title>Multimodal Machine Learning: A Survey and Taxonomy</title>
    <link href="https://10ng1000.github.io/2023/10/15/Multimodal-Machine-Learning-A-Survey-and-Taxonomy/"/>
    <id>https://10ng1000.github.io/2023/10/15/Multimodal-Machine-Learning-A-Survey-and-Taxonomy/</id>
    <published>2023-10-15T03:19:31.000Z</published>
    <updated>2024-08-23T06:08:36.345Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><p>一般来说，模态就是指，一种事情发生或者被经历的方法。</p><p>当一个研究的问题或者说数据集包含了多个模态时，就是多模态问题或者多模态数据集。</p><p>多模态数据主要有：自然语言；视觉信号；音频信号等。<br>我认为多模态主要包括这些，是因为这些信息是日常生活红数据量最丰富、最有价值和最容易获取的信息，在当下最具有研究价值；而一些其他的信息，像是红外、超声、嗅觉、触觉、加速度信号等，可能只会在机器人等限定的领域有用处，相对来说应用范围没有那么广泛，信号的局限性较大。</p><p>多模态的五大挑战：表示，转换，对齐，融合，协同学习<br>这几大方面的挑战是：<br>表示：怎样表示、总结不同模态的信息。不同模态的数据经常是异质的，比如语言是符号性的，音频和视频是用信号表示的。<br>转换：不同模态之间的联系可能是开放的，比如一个图片可以有多种语言解释。<br>对齐：把不同的模态直接联系起来，比如把做菜的步骤关联到对应的视频。<br>融合：把不同模态的数据综合起来做预测。<br>协同学习：把一种模态的学习模型迁移到另一个模态的模型中</p><p>我认为这几个问题中，表示主要是数据处理层面的，涉及到模型如何设计、数据怎样表示；翻译和对齐可以是模型的一部分能力，也可以是这个多模态模型的功能；融合主要是涉及到模型的输出部分；而协同学习则是和迁移学习相似，主要是对模型开发人员有用。我认为这几个问题中最有挑战性的可能是协同学习，因为不同模态之间的模型差异实在太大，感觉这样的机制很难实现。</p><h1 id="2-多模态的应用："><a href="#2-多模态的应用：" class="headerlink" title="2 多模态的应用："></a>2 多模态的应用：</h1><p>1.视听结合的言语识别，图像注解等 V-A<br>多模态可以增强模型的鲁棒性<br>2.多媒体内容的索引和检索 V-A<br>3.人类社交时的多模态行为的理解 V-A<br>4.媒体解释 V-L<br>5.事件检测 V-L<br>6.多媒体生成 V-L</p><p>跨模态检索会用到除了融合以外的所有技术</p><h1 id="3-表示"><a href="#3-表示" class="headerlink" title="3 表示"></a>3 表示</h1><p>把多模态的数据用计算模型可以识别的格式表示出来，可以是向量&#x2F;张量表示。<br>困难  </p><ol><li>结合异质数据  </li><li>处理不同的噪音  </li><li>处理丢失的数据<br>现在很多的多模态数据的表示都是单模态数据的简单拼接。</li></ol><p>好的表示的特点：平滑、保留时空顺序、稀疏、自然聚类</p><h3 id="联合表示："><a href="#联合表示：" class="headerlink" title="联合表示："></a>联合表示：</h3><p>联合表示把多个单模态数据结合到相同的表示空间 。<br>通常用在多模态数据要结合起来使用的时候<br>AVSR，情感分析，多模态手势识别等</p><p>神经网络<br>通常把最后一层或者倒数第二层拿来用<br>1.先分别用独立层训练，然后通过一个隐藏层来把这些模态投影到一个联合的空间中<br>2.对于没有标签的数据，可以用自编码器<br>基于联合表示的神经网络的一大好处是：<br>可以学习无标签数据，而且可以微调来适应特殊的任务</p><p>概率图模型<br>使用DBM等<br>优点：泛化性好，可以更好地处理缺失模态的数据<br>缺点：难以训练，计算代价高</p><p>序列表示<br>使用RNN</p><h3 id="协同表示："><a href="#协同表示：" class="headerlink" title="协同表示："></a>协同表示：</h3><p>协同表示分别处理单模态信号，同时保留有相似的约束。<br>通常用在一次只使用一种模态数据的时候<br>比如多模态检索、翻译、结合、零次学习</p><p>相似模型：<br>最小化不同模态间在坐标空间的距离<br>可以使用神经网络，可以端到端学习协同表示(RNN\LSTM等)</p><p>结构化坐标空间：<br>添加了额外的限制<br>主要形式有跨模态哈希、图像和语言的顺序嵌入、典型关联分析：<br>把高纬度数据压缩到低纬度，相似的对象有相似的码<br>可以使用神经网络</p><h1 id="4-翻译"><a href="#4-翻译" class="headerlink" title="4.翻译"></a>4.翻译</h1><p>给出一个模态的实体，生成在另一个模态的相同的实体<br>例子：语音合成，视觉语音生成，视频描述，跨模态检索<br>两种类型：基于样例的，生成式的</p><h2 id="4-1-基于样例的：使用字典"><a href="#4-1-基于样例的：使用字典" class="headerlink" title="4.1 基于样例的：使用字典"></a>4.1 基于样例的：使用字典</h2><p>使用两类算法：基于检索的，基于结合的<br>基于检索的：直接使用检索，可用单模态空间或者跨媒体语义空间，后者更好，可以双向翻译<br>基于结合的：使用更复杂的规则，把多个结果结合起来生成一个更好的翻译<br>缺点：模型大、查询慢、字典要求大、不一定有对应结果</p><h2 id="4-2-生成式的：生成模型"><a href="#4-2-生成式的：生成模型" class="headerlink" title="4.2 生成式的：生成模型"></a>4.2 生成式的：生成模型</h2><p>类型：基于语法的，编码解码器（最常用），持续生成模型</p><p>基于语法的：用语法限制目标域<br>优势：更可能生成语法和逻辑正确的结果<br>局限：智能产生公式化的结果，难以创新；训练过程要分段、复杂</p><p>编码解码器：先编码到一个隐表示，然后再用解码器解码<br>使用端到端的神经网络，编码通常和模态本身有关，解码通常用RNN和LSTM。缺点是需要大量数据，而且神经网络可能是再记忆训练数据</p><p>持续生成模型：基于源模态数据流持续生成目标模态，最适合时序序列，例如文字转语音</p><h2 id="4-3-模型评估"><a href="#4-3-模型评估" class="headerlink" title="4.3 模型评估"></a>4.3 模型评估</h2><p>一种评估方法是人工判断：<br>语音合成：自然度，平均观点分数<br>VSS：真实度<br>媒体描述：语法语义正确，相关度，顺序，细节<br>自动评估效果一般</p><p>也可以用检索来作为描述的评估方法</p><h1 id="5-对齐"><a href="#5-对齐" class="headerlink" title="5 对齐"></a>5 对齐</h1><p>找到不同模态之间的子模块实体之间的联系和对应关系<br>两种对齐：显式和隐式</p><h2 id="5-1-显式对齐"><a href="#5-1-显式对齐" class="headerlink" title="5.1 显式对齐"></a>5.1 显式对齐</h2><p>最重要的方式是用相似矩阵来评价</p><p>无监督：不需要对齐的标签<br>假设对齐有限制，例如时间顺序，或者相似矩阵存在<br>DTW用于对齐多视角时间序列，CCA。可以同时学习相似矩阵和对齐<br>图模型，需要专家知识。</p><p>有监督：需要有标签的对齐实例<br>方法和无监督的比较像</p><p>深度学习也在显式对齐里面很好用，LSTM，CNN</p><h2 id="5-2-隐式对齐"><a href="#5-2-隐式对齐" class="headerlink" title="5.2 隐式对齐"></a>5.2 隐式对齐</h2><p>是其他任务中间的步骤，通常是隐式的<br>不依赖于有监督的样本</p><p>图模型：需要人工设定对齐方式，比较不常用</p><p>神经网络：最常用的方法，尤其是在翻译的中间步骤，可以给翻译带来很大的提升，加入注意力机制效果更好</p><h2 id="5-3-难点"><a href="#5-3-难点" class="headerlink" title="5.3 难点"></a>5.3 难点</h2><p>标签数据少，相似矩阵难设计，对齐关系可能是多对多，或者不存在</p><h1 id="6-融合"><a href="#6-融合" class="headerlink" title="6 融合"></a>6 融合</h1><p>集成多个模态的信息来做预测，一般认为是在预测的后部阶段</p><ol><li>更健壮的预测结果</li><li>可以捕捉到补充的信息</li><li>缺失一个维度的信息时仍可以起作用</li></ol><h2 id="6-1-模型无关的方法"><a href="#6-1-模型无关的方法" class="headerlink" title="6.1 模型无关的方法"></a>6.1 模型无关的方法</h2><p>可以分为早期，晚期和杂交融合<br>比较简单，但是不能充分利用多模态的特点</p><h2 id="6-2-基于模型的方法"><a href="#6-2-基于模型的方法" class="headerlink" title="6.2 基于模型的方法"></a>6.2 基于模型的方法</h2><p>基于核的方法：<br>不同的模态使用不同的核，核可以看成数据点的相似函数<br>优点是损失函数是凸的，好优化；<br>缺点是测试时也要用训练数据，查询慢，内存消耗大</p><p>图模型：<br>生成式的：建模联合概率<br>判别式的：建模条件概率<br>优点：容易利用数据的时间和空间结构，所以在AVSR和情感检测常用；可以加入专家知识</p><p>神经网络：最常用<br>优势：可以从大量的数据中学习；端到端训练；效果好<br>缺点：可解释性差，需要大量数据</p><p>融合的困难：<br>数据可能没有在时间上对齐<br>难以捕捉互补的信息<br>每个模态都可能会有噪音</p><h1 id="7-共同学习"><a href="#7-共同学习" class="headerlink" title="7 共同学习"></a>7 共同学习</h1><p>用另一个模态的模型知识来辅助一个模态的模型学习<br>这是与任务无关的，因此可以在多模态融合、翻译、对齐模型中使用</p><h2 id="7-1-平行数据"><a href="#7-1-平行数据" class="headerlink" title="7.1 平行数据"></a>7.1 平行数据</h2><p>不同模态使用一个数据集，对应关系已经确定<br>共同训练：创建更多有标签数据<br>迁移学习：可以多模态表示，单模态的时候也更好</p><h2 id="7-2-不平行数据"><a href="#7-2-不平行数据" class="headerlink" title="7.2 不平行数据"></a>7.2 不平行数据</h2><p>不需要有共享的实例，只需要有共享的概念或类别<br>迁移学习<br>概念建构：通过不仅仅是语言，也包含其他模态的数据来学习语义<br>零次学习：不需要之前见过任何相关的有标签的数据，就识别出一个概念<br>单模态：通过部分特征来推出实体<br>多模态：使用另一个模态来推出没有认识的模态</p><h2 id="7-3-混合数据"><a href="#7-3-混合数据" class="headerlink" title="7.3 混合数据"></a>7.3 混合数据</h2><p>两个模态用一个共享的模态或者数据集来桥接</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1 介绍&quot;&gt;&lt;/a&gt;1 介绍&lt;/h1&gt;&lt;p&gt;一般来说，模态就是指，一种事情发生或者被经历的方法。&lt;/p&gt;
&lt;p&gt;当一个研究的问题或者说数据集包含了多个模态时，就是多模态</summary>
      
    
    
    
    
    <category term="note" scheme="https://10ng1000.github.io/tags/note/"/>
    
  </entry>
  
</feed>
